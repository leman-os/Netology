# Домашнее задание к занятию "3.5. Файловые системы"

1. Узнайте о [sparse](https://ru.wikipedia.org/wiki/Разрежённый_файл) (разряженных) файлах.

   **Ответ:**

   Узнал. Используется для экономии пространства. Вместо последовательности нулей записывает описание последовательности.

2. Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?

   Не могут. Т.к. хардлинк не является файлом, поэтому права и логический диск у всех хардлинков будут одинаковые. Проще говоря, права привязываются к Inode. В случае с хардлинками у всех Inode будет одинаковым.

3. Сделайте `vagrant destroy` на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

   ```
   Vagrant.configure("2") do |config|
     config.vm.box = "bento/ubuntu-20.04"
     config.vm.provider :virtualbox do |vb|
       lvm_experiments_disk0_path = "/tmp/lvm_experiments_disk0.vmdk"
       lvm_experiments_disk1_path = "/tmp/lvm_experiments_disk1.vmdk"
       vb.customize ['createmedium', '--filename', lvm_experiments_disk0_path, '--size', 2560]
       vb.customize ['createmedium', '--filename', lvm_experiments_disk1_path, '--size', 2560]
       vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk0_path]
       vb.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 2, '--device', 0, '--type', 'hdd', '--medium', lvm_experiments_disk1_path]
     end
   end
   ```

   Данная конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2.5 Гб.

   **Ответ:**

   ```
   vagrant@vagrant:~$ sudo fdisk -l | grep sd[b-z]
   Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   ```

4. Используя `fdisk`, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.

   **Ответ:**

   ```
   vagrant@vagrant:~$ sudo fdisk /dev/sdb
   Command (m for help): g
   Created a new GPT disklabel (GUID: AD6C426E-C620-5848-8ED7-5E6EF0DE6B95).
   The old dos signature will be removed by a write command.
   
   Command (m for help): n
   Partition number (1-128, default 1): 1
   First sector (2048-5242846, default 2048):
   Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-5242846, default 5242846): +2G
   
   Created a new partition 1 of type 'Linux filesystem' and of size 2 GiB.
   
   Command (m for help): p
   Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   Disk model: VBOX HARDDISK
   Units: sectors of 1 * 512 = 512 bytes
   Sector size (logical/physical): 512 bytes / 512 bytes
   I/O size (minimum/optimal): 512 bytes / 512 bytes
   Disklabel type: gpt
   Disk identifier: AD6C426E-C620-5848-8ED7-5E6EF0DE6B95
   
   Device     Start     End Sectors Size Type
   /dev/sdb1   2048 4196351 4194304   2G Linux filesystem
   
   Command (m for help): n
   Partition number (2-128, default 2):
   First sector (4196352-5242846, default 4196352):
   Last sector, +/-sectors or +/-size{K,M,G,T,P} (4196352-5242846, default 5242846):
   
   Created a new partition 2 of type 'Linux filesystem' and of size 511 MiB.
   
   Command (m for help): p
   Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   Disk model: VBOX HARDDISK
   Units: sectors of 1 * 512 = 512 bytes
   Sector size (logical/physical): 512 bytes / 512 bytes
   I/O size (minimum/optimal): 512 bytes / 512 bytes
   Disklabel type: gpt
   Disk identifier: AD6C426E-C620-5848-8ED7-5E6EF0DE6B95
   
   Device       Start     End Sectors  Size Type
   /dev/sdb1     2048 4196351 4194304    2G Linux filesystem
   /dev/sdb2  4196352 5242846 1046495  511M Linux filesystem
   ```

5. Используя `sfdisk`, перенесите данную таблицу разделов на второй диск.

   **Ответ:**

   Мучался с root правами при пайпе. Нашел решение.

   ```
   vagrant@vagrant:~$ sudo sfdisk -d /dev/sdb | sudo sfdisk --force /dev/sdc
   Checking that no-one is using this disk right now ... OK
   
   Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   Disk model: VBOX HARDDISK
   Units: sectors of 1 * 512 = 512 bytes
   Sector size (logical/physical): 512 bytes / 512 bytes
   I/O size (minimum/optimal): 512 bytes / 512 bytes
   
   >>> Script header accepted.
   >>> Script header accepted.
   >>> Script header accepted.
   >>> Script header accepted.
   >>> Script header accepted.
   >>> Script header accepted.
   >>> Created a new GPT disklabel (GUID: AD6C426E-C620-5848-8ED7-5E6EF0DE6B95).
   /dev/sdc1: Created a new partition 1 of type 'Linux filesystem' and of size 2 GiB.
   /dev/sdc2: Created a new partition 2 of type 'Linux filesystem' and of size 511 MiB.
   /dev/sdc3: Done.
   
   New situation:
   Disklabel type: gpt
   Disk identifier: AD6C426E-C620-5848-8ED7-5E6EF0DE6B95
   
   Device       Start     End Sectors  Size Type
   /dev/sdc1     2048 4196351 4194304    2G Linux filesystem
   /dev/sdc2  4196352 5242846 1046495  511M Linux filesystem
   
   The partition table has been altered.
   Calling ioctl() to re-read partition table.
   Syncing disks.
   vagrant@vagrant:~$ sudo fdisk -l | grep sd[b-z]
   Disk /dev/sdb: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   /dev/sdb1     2048 4196351 4194304    2G Linux filesystem
   /dev/sdb2  4196352 5242846 1046495  511M Linux filesystem
   Disk /dev/sdc: 2.51 GiB, 2684354560 bytes, 5242880 sectors
   /dev/sdc1     2048 4196351 4194304    2G Linux filesystem
   /dev/sdc2  4196352 5242846 1046495  511M Linux filesystem
   ```

6. Соберите `mdadm` RAID1 на паре разделов 2 Гб.

   **Ответ:**

   ```
   vagrant@vagrant:~$ sudo mdadm -C -v /dev/md0 -l 1 -n 2 /dev/sd[b,c]1
   mdadm: Note: this array has metadata at the start and
       may not be suitable as a boot device.  If you plan to
       store '/boot' on this device please ensure that
       your boot-loader understands md/v1.x metadata, or use
       --metadata=0.90
   mdadm: size set to 2094080K
   Continue creating array? y
   mdadm: Defaulting to version 1.2 metadata
   mdadm: array /dev/md0 started.
   vagrant@vagrant:~$ lsblk
   NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
   loop0                       7:0    0 67.2M  1 loop  /snap/lxd/21835
   loop1                       7:1    0 61.9M  1 loop  /snap/core20/1328
   loop2                       7:2    0 43.6M  1 loop  /snap/snapd/14978
   loop3                       7:3    0   47M  1 loop  /snap/snapd/16010
   loop4                       7:4    0 61.9M  1 loop  /snap/core20/1518
   loop5                       7:5    0 67.8M  1 loop  /snap/lxd/22753
   sda                         8:0    0   64G  0 disk
   ├─sda1                      8:1    0    1M  0 part
   ├─sda2                      8:2    0  1.5G  0 part  /boot
   └─sda3                      8:3    0 62.5G  0 part
     └─ubuntu--vg-ubuntu--lv 253:0    0 31.3G  0 lvm   /
   sdb                         8:16   0  2.5G  0 disk
   ├─sdb1                      8:17   0    2G  0 part
   │ └─md0                     9:0    0    2G  0 raid1
   └─sdb2                      8:18   0  511M  0 part
   sdc                         8:32   0  2.5G  0 disk
   ├─sdc1                      8:33   0    2G  0 part
   │ └─md0                     9:0    0    2G  0 raid1
   └─sdc2                      8:34   0  511M  0 part
   ```

7. Соберите `mdadm` RAID0 на второй паре маленьких разделов.

   **Ответ:**

   ```
   vagrant@vagrant:~$ sudo mdadm -C -v /dev/md1 -l 0 -n 2 /dev/sd[b,c]2
   mdadm: chunk size defaults to 512K
   mdadm: Defaulting to version 1.2 metadata
   mdadm: array /dev/md1 started.
   vagrant@vagrant:~$ lsblk
   NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
   loop0                       7:0    0 67.2M  1 loop  /snap/lxd/21835
   loop1                       7:1    0 61.9M  1 loop  /snap/core20/1328
   loop2                       7:2    0 43.6M  1 loop  /snap/snapd/14978
   loop3                       7:3    0   47M  1 loop  /snap/snapd/16010
   loop4                       7:4    0 61.9M  1 loop  /snap/core20/1518
   loop5                       7:5    0 67.8M  1 loop  /snap/lxd/22753
   sda                         8:0    0   64G  0 disk
   ├─sda1                      8:1    0    1M  0 part
   ├─sda2                      8:2    0  1.5G  0 part  /boot
   └─sda3                      8:3    0 62.5G  0 part
     └─ubuntu--vg-ubuntu--lv 253:0    0 31.3G  0 lvm   /
   sdb                         8:16   0  2.5G  0 disk
   ├─sdb1                      8:17   0    2G  0 part
   │ └─md0                     9:0    0    2G  0 raid1
   └─sdb2                      8:18   0  511M  0 part
     └─md1                     9:1    0 1017M  0 raid0
   sdc                         8:32   0  2.5G  0 disk
   ├─sdc1                      8:33   0    2G  0 part
   │ └─md0                     9:0    0    2G  0 raid1
   └─sdc2                      8:34   0  511M  0 part
     └─md1                     9:1    0 1017M  0 raid0
   ```

8. Создайте 2 независимых PV на получившихся md-устройствах.

   **Ответ:**

   ```
   sudo pvcreate /dev/md0 /dev/md1
     Physical volume "/dev/md0" successfully created.
     Physical volume "/dev/md1" successfully created.
   vagrant@vagrant:~$ sudo pvscan
     PV /dev/sda3   VG ubuntu-vg       lvm2 [<62.50 GiB / 31.25 GiB free]
     PV /dev/md0                       lvm2 [<2.00 GiB]
     PV /dev/md1                       lvm2 [1017.00 MiB]
     Total: 3 [<65.49 GiB] / in use: 1 [<62.50 GiB] / in no VG: 2 [2.99 GiB]
   ```

9. Создайте общую volume-group на этих двух PV.

   **Ответ:**

   ```
   vagrant@vagrant:~$ sudo vgcreate vol_gr1 /dev/md1 /dev/md0
     Volume group "vol_gr1" successfully created
   vagrant@vagrant:~$ sudo vgdisplay
     --- Volume group ---
     VG Name               ubuntu-vg
     System ID             
     Format                lvm2
     Metadata Areas        1
     Metadata Sequence No  2
     VG Access             read/write
     VG Status             resizable
     MAX LV                0
     Cur LV                1
     Open LV               1
     Max PV                0
     Cur PV                1
     Act PV                1
     VG Size               <63.00 GiB
     PE Size               4.00 MiB
     Total PE              16127
     Alloc PE / Size       8064 / 31.50 GiB
     Free  PE / Size       8063 / <31.50 GiB
     VG UUID               aK7Bd1-JPle-i0h7-5jJa-M60v-WwMk-PFByJ7
      
     --- Volume group ---
     VG Name               vol_gr1
     System ID             
     Format                lvm2
     Metadata Areas        2
     Metadata Sequence No  1
     VG Access             read/write
     VG Status             resizable
     MAX LV                0
     Cur LV                0
     Open LV               0
     Max PV                0
     Cur PV                2
     Act PV                2
     VG Size               <2.99 GiB
     PE Size               4.00 MiB
     Total PE              765
     Alloc PE / Size       0 / 0   
     Free  PE / Size       765 / <2.99 GiB
     VG UUID               cI2Dx4-mNIT-PWM1-I4cd-h2bA-xeAM-171FoI
   ```

10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.

    **Ответ:**

    ```
    vagrant@vagrant:~$ sudo lvcreate -L 100M vol_gr1 /dev/md0
      Logical volume "lvol0" created.
    ```

11. Создайте `mkfs.ext4` ФС на получившемся LV.

    **Ответ:**

    ```
    vagrant@vagrant:~$ sudo mkfs.ext4 /dev/vol_gr1/lvol0
    mke2fs 1.45.5 (07-Jan-2020)
    Creating filesystem with 25600 4k blocks and 25600 inodes
    
    Allocating group tables: done                            
    Writing inode tables: done                            
    Creating journal (1024 blocks): done
    Writing superblocks and filesystem accounting information: done
    ```

12. Смонтируйте этот раздел в любую директорию, например, `/tmp/new`.

    **Ответ:**

    Пока не понятно, это разовое монтирование или надо на постоянку. Делаю на постоянку.

    ```
    vagrant@vagrant:~$ mkdir /tmp/new
    vagrant@vagrant:~$ sudo  mount /dev/vol_gr1/lvol0 /tmp/new
    vagrant@vagrant:~$ df -h | grep lvol0
    /dev/mapper/vol_gr1-lvol0           93M   72K   86M   1% /tmp/new
    ```

13. Поместите туда тестовый файл, например `wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz`.

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ sudo wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz
    --2022-06-26 15:20:59--  https://mirror.yandex.ru/ubuntu/ls-lR.gz
    Resolving mirror.yandex.ru (mirror.yandex.ru)... 213.180.204.183, 2a02:6b8::183
    Connecting to mirror.yandex.ru (mirror.yandex.ru)|213.180.204.183|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 23589547 (22M) [application/octet-stream]
    Saving to: ‘/tmp/new/test.gz’
    
    /tmp/new/test.gz                             100%[============================================================================================>]  22.50M  13.0MB/s    in 1.7s    
    
    2022-06-26 15:21:01 (13.0 MB/s) - ‘/tmp/new/test.gz’ saved [23589547/23589547]
    ```

14. Прикрепите вывод `lsblk`.

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ lsblk
    NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
    loop1                       7:1    0 55.4M  1 loop  /snap/core18/2128
    loop2                       7:2    0 70.3M  1 loop  /snap/lxd/21029
    loop3                       7:3    0 55.5M  1 loop  /snap/core18/2409
    loop4                       7:4    0   47M  1 loop  /snap/snapd/16010
    loop5                       7:5    0 61.9M  1 loop  /snap/core20/1518
    loop6                       7:6    0 67.8M  1 loop  /snap/lxd/22753
    sda                         8:0    0   64G  0 disk  
    ├─sda1                      8:1    0    1M  0 part  
    ├─sda2                      8:2    0    1G  0 part  /boot
    └─sda3                      8:3    0   63G  0 part  
      └─ubuntu--vg-ubuntu--lv 253:0    0 31.5G  0 lvm   /
    sdb                         8:16   0  2.5G  0 disk  
    ├─sdb1                      8:17   0    2G  0 part  
    │ └─md0                     9:0    0    2G  0 raid1 
    │   └─vol_gr1-lvol0       253:1    0  100M  0 lvm   /tmp/new
    └─sdb2                      8:18   0  511M  0 part  
      └─md1                     9:1    0 1017M  0 raid0 
    sdc                         8:32   0  2.5G  0 disk  
    ├─sdc1                      8:33   0    2G  0 part  
    │ └─md0                     9:0    0    2G  0 raid1 
    │   └─vol_gr1-lvol0       253:1    0  100M  0 lvm   /tmp/new
    └─sdc2                      8:34   0  511M  0 part  
      └─md1                     9:1    0 1017M  0 raid0 
    ```

15. Протестируйте целостность файла:

    ```
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ gzip -t /tmp/new/test.gz
    vagrant@vagrant:/tmp/new$ echo $?
    0
    ```

16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ sudo pvmove /dev/md0
      /dev/md0: Moved: 40.00%
      /dev/md0: Moved: 100.00%
    vagrant@vagrant:/tmp/new$ lsblk
    NAME                      MAJ:MIN RM  SIZE RO TYPE  MOUNTPOINT
    loop1                       7:1    0 55.4M  1 loop  /snap/core18/2128
    loop2                       7:2    0 70.3M  1 loop  /snap/lxd/21029
    loop3                       7:3    0 55.5M  1 loop  /snap/core18/2409
    loop4                       7:4    0   47M  1 loop  /snap/snapd/16010
    loop5                       7:5    0 61.9M  1 loop  /snap/core20/1518
    loop6                       7:6    0 67.8M  1 loop  /snap/lxd/22753
    sda                         8:0    0   64G  0 disk  
    ├─sda1                      8:1    0    1M  0 part  
    ├─sda2                      8:2    0    1G  0 part  /boot
    └─sda3                      8:3    0   63G  0 part  
      └─ubuntu--vg-ubuntu--lv 253:0    0 31.5G  0 lvm   /
    sdb                         8:16   0  2.5G  0 disk  
    ├─sdb1                      8:17   0    2G  0 part  
    │ └─md0                     9:0    0    2G  0 raid1 
    └─sdb2                      8:18   0  511M  0 part  
      └─md1                     9:1    0 1017M  0 raid0 
        └─vol_gr1-lvol0       253:1    0  100M  0 lvm   /tmp/new
    sdc                         8:32   0  2.5G  0 disk  
    ├─sdc1                      8:33   0    2G  0 part  
    │ └─md0                     9:0    0    2G  0 raid1 
    └─sdc2                      8:34   0  511M  0 part  
      └─md1                     9:1    0 1017M  0 raid0 
        └─vol_gr1-lvol0       253:1    0  100M  0 lvm   /tmp/new
    ```

17. Сделайте `--fail` на устройство в вашем RAID1 md.

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ sudo mdadm /dev/md0 --fail /dev/sdb1
    mdadm: set /dev/sdb1 faulty in /dev/md0
    vagrant@vagrant:/tmp/new$ sudo mdadm -D /dev/md0
    /dev/md0:
               Version : 1.2
         Creation Time : Sun Jun 26 15:11:14 2022
            Raid Level : raid1
            Array Size : 2094080 (2045.00 MiB 2144.34 MB)
         Used Dev Size : 2094080 (2045.00 MiB 2144.34 MB)
          Raid Devices : 2
         Total Devices : 2
           Persistence : Superblock is persistent
    
           Update Time : Sun Jun 26 15:33:35 2022
                 State : clean, degraded 
        Active Devices : 1
       Working Devices : 1
        Failed Devices : 1
         Spare Devices : 0
    
    Consistency Policy : resync
    
                  Name : vagrant:0  (local to host vagrant)
                  UUID : 6f80f0d2:e9356399:cd78d899:4365e596
                Events : 19
    
        Number   Major   Minor   RaidDevice State
           -       0        0        0      removed
           1       8       33        1      active sync   /dev/sdc1
    
           0       8       17        -      faulty   /dev/sdb1
    ```

18. Подтвердите выводом `dmesg`, что RAID1 работает в деградированном состоянии.

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ sudo dmesg |grep md0
    [  242.743894] md/raid1:md0: not clean -- starting background reconstruction
    [  242.743896] md/raid1:md0: active with 2 out of 2 mirrors
    [  242.743910] md0: detected capacity change from 0 to 2144337920
    [  242.744344] md: resync of RAID array md0
    [  253.263714] md: md0: resync done.
    [ 1582.780948] md/raid1:md0: Disk failure on sdb1, disabling device.
                   md/raid1:md0: Operation continuing on 1 devices.
    ```

19. Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен:

    ```
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```

    **Ответ:**

    ```
    vagrant@vagrant:/tmp/new$ gzip -t /tmp/new/test.gz
    vagrant@vagrant:/tmp/new$ echo $?
    0
    ```

20. Погасите тестовый хост, `vagrant destroy`.

```
~/Netology/Linux ⌚ 18:36:52
$ vagrant destroy
    default: Are you sure you want to destroy the 'default' VM? [y/N] y
==> default: Forcing shutdown of VM...
==> default: Destroying VM and associated drives...
```